{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make(\"CartPole-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward for this episode was: 15.0\n",
      "Reward for this episode was: 12.0\n",
      "Reward for this episode was: 20.0\n",
      "Reward for this episode was: 15.0\n",
      "Reward for this episode was: 17.0\n",
      "Reward for this episode was: 18.0\n",
      "Reward for this episode was: 50.0\n",
      "Reward for this episode was: 15.0\n",
      "Reward for this episode was: 39.0\n",
      "Reward for this episode was: 17.0\n"
     ]
    }
   ],
   "source": [
    "# Try running environment with random actions\n",
    "env.reset()\n",
    "reward_sum = 0\n",
    "num_games = 10\n",
    "num_game = 0\n",
    "while num_game < num_games:\n",
    "    env.render()\n",
    "    observation, reward, done, _ = env.step(env.action_space.sample())\n",
    "    reward_sum += reward\n",
    "    if done:\n",
    "        print(\"Reward for this episode was: {}\".format(reward_sum))\n",
    "        reward_sum = 0\n",
    "        num_game += 1\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_population(env, size=1, mean=0, std=1):\n",
    "    \"\"\" Creates a population \"\"\"\n",
    "    params = env.observation_space.shape[0]  # Parameters in our environment state\n",
    "    action_space = env.action_space.n # Possible actions\n",
    "    if mean is None:\n",
    "        # No mean specified, assume mean of zero\n",
    "        mean = np.zeros((params, action_space)) \n",
    "    if std is None:\n",
    "        # No standard deviation specified, assume standard deviation of 1\n",
    "        std = np.ones((params,action_space))\n",
    "    \n",
    "    # Create a population based on a normal distribution given the mean and std provided\n",
    "    pop = np.random.normal(mean,std,size=[size,params,action_space])\n",
    "    \n",
    "    return pop\n",
    "\n",
    "def mutate(population, prob_mutate, std):\n",
    "    \"\"\" Mutates a population based on normal distribution \"\"\"\n",
    "    # Create a mask of 0s and 1s that are used to determine whether a mutation will take place or not \n",
    "    # on the attribute level for each member \n",
    "    mutation_mask = np.random.choice([0,1], size=population.shape, p=[1-prob_mutate, prob_mutate])\n",
    "    \n",
    "    # Create a mutation based on a normal distribution\n",
    "    mutation = np.random.normal(0, std, size=population.shape)\n",
    "    \n",
    "    # Apply the mutation mask\n",
    "    mutation *= mutation_mask\n",
    "    \n",
    "    return population + mutation # Add the mutation to the population\n",
    "\n",
    "def breed(population):\n",
    "    \"\"\" Breeds a population with itself. Each individual is paired up with another individual from the same\n",
    "        population and their values are chosen with a 50 / 50 chance of the offspring acquiring a value from\n",
    "        either parent.\n",
    "    \"\"\"\n",
    "    parent_1 = population.copy()\n",
    "    parent_2 = population.copy()\n",
    "    \n",
    "    np.random.shuffle(parent_2) # Mix up one of the parent's ordering so we can just align them randomly\n",
    "    \n",
    "    # Used to determine if parent one attribute will be inherited\n",
    "    parent_1_mask = np.random.choice([0,1],size=population.shape)\n",
    "    \n",
    "    # If parent two's attribute will be inherited\n",
    "    parent_2_mask = (parent_1_mask + 1) % 2\n",
    "    \n",
    "    return parent_1 * parent_1_mask + parent_2 * parent_2_mask\n",
    "\n",
    "def normalize(env,state):\n",
    "    \"\"\" Normalizes state to range from 0 to 1 \"\"\"\n",
    "    if env.observation_space.low == float(\"inf\"):\n",
    "        # Some observation spaces are infinite, in which case we won't normalize\n",
    "        lo = 0\n",
    "        hi = 1\n",
    "    else:\n",
    "        lo = env.observation_space.low\n",
    "        hi = env.observation_space.high\n",
    "    return (state - lo) / (hi - lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(env, ind, trials=1, render=False):\n",
    "    \"\"\" Scores an individual bot in the environment. Returns mean score \"\"\"\n",
    "    rewards = 0\n",
    "    for trial in range(trials):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "            num_moves =+ 1\n",
    "            out = np.dot(state,ind)\n",
    "            action = np.argmax(out)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            rewards += reward\n",
    "    env.close()\n",
    "    return rewards / float(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_rate = 0.01\n",
    "prob_mutate = 0.25\n",
    "std = 1\n",
    "std_decay = 0.9\n",
    "num_episodes = 30\n",
    "print_every = 100\n",
    "pop_size = 25\n",
    "trials_per_individual = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, pop_size, trials_per_individual, survival_rate, prob_mutate, std, num_episodes, std_decay=0.9, curiousity=False, verbose=False, goal=200):\n",
    "    \"\"\" Trains a bot based on an envolutionary model \"\"\"\n",
    "    params = env.observation_space.shape[0] # Determine the number of parameters our environment has\n",
    "    pop = create_population(env, pop_size) # Create the population\n",
    "    pop_survive = max(1,int(pop_size * survival_rate)) # Set the number of individuals that will survive after each episode\n",
    "    best_score = float(\"-inf\") # Track best score\n",
    "    for episode in range(num_episodes):\n",
    "        # Score individuals\n",
    "        scores = [score(env, ind, trials=trials_per_individual, curiousity=curiousity) for ind in pop]\n",
    "        \n",
    "        # Convert to list\n",
    "        pop_scores = zip(pop,scores)\n",
    "        \n",
    "        # Sort by how well each individual did\n",
    "        pop_scores = sorted(pop_scores, key=lambda pop_score: pop_score[1], reverse=True)\n",
    "        \n",
    "        pop_scores = list(zip(*pop_scores)) # Apply scores to individuals\n",
    "        pop, scores = pop_scores # Break apart population and scores\n",
    "        pop = pop[:pop_survive] # Only keep the best\n",
    "        pop = np.array(pop) \n",
    "        pop = np.vstack([pop, breed(pop)]) # Breed the population and append to existing population\n",
    "        pop = np.vstack([pop, mutate(pop, prob_mutate, std)]) # Mutate the population and append to existing population\n",
    "        \n",
    "        # Determine how many new individuals to introduct to keep population number constant\n",
    "        remaining_pop = max(0, pop_size - len(pop)) \n",
    "        \n",
    "        # Determine the mean of the population parameters\n",
    "        mean = np.mean(create_population(env,size=10,mean=0, std=1),axis=0)\n",
    "        \n",
    "        # Add new members to population\n",
    "        new_pop = create_population(env, size=remaining_pop,mean=mean, std=std)\n",
    "        pop = np.vstack([pop, new_pop])\n",
    "\n",
    "        if verbose:\n",
    "            print(\"episode: {} best score: {:0.2f}\".format(episode, scores[0]))\n",
    "\n",
    "        if scores[0] > best_score:\n",
    "            # If best score is better than prior best score, decay the standard deviation since we're\n",
    "            # likely getting to an optimal individual and we want variant to decrease\n",
    "            std *= std_decay\n",
    "            best_score = scores[0]\n",
    "        else:\n",
    "            # Prior best score not reached, increase standard deviation to add more variety and hopefully\n",
    "            # break through any plateaus\n",
    "            std /= std_decay\n",
    "            \n",
    "        if best_score >= goal:\n",
    "            if verbose:\n",
    "                print(\"training complete in {} episodes\".format(episode))\n",
    "            break\n",
    "    return pop[0] # Return best invidual after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(env, ind, trials=1, curiousity=False, render=False):\n",
    "    rewards = 0\n",
    "    for trial in range(trials):\n",
    "        state = env.reset()\n",
    "        min_state = state\n",
    "        max_state = state\n",
    "        \n",
    "        done = False\n",
    "        while not done:\n",
    "            if render:\n",
    "                env.render()\n",
    "            num_moves =+ 1\n",
    "            out = np.dot(state,ind)\n",
    "            action = np.argmax(out)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            min_state = np.min([min_state, state],axis=0)\n",
    "            max_state = np.max([max_state, state],axis=0)\n",
    "            rewards += reward\n",
    "        if curiousity:\n",
    "            # Apply some value to exploration. This will nudge the algorithm in favor of bots that explore\n",
    "            # more of the environment space.\n",
    "            rewards += np.sum(max_state - min_state)\n",
    "    env.close()\n",
    "    return rewards / float(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 best score: 201.99562157873646\n",
      "training complete in 0 episodes\n"
     ]
    }
   ],
   "source": [
    "bot = train(env, pop_size, trials_per_individual, survival_rate, prob_mutate, std, num_episodes, curiousity=True, verbose=True, goal=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 best score: -200.0\n",
      "episode: 1 best score: -200.0\n",
      "episode: 2 best score: -200.0\n",
      "episode: 3 best score: -200.0\n",
      "episode: 4 best score: -200.0\n",
      "episode: 5 best score: -200.0\n",
      "episode: 6 best score: -200.0\n",
      "episode: 7 best score: -200.0\n",
      "episode: 8 best score: -200.0\n",
      "episode: 9 best score: -130.0\n",
      "episode: 10 best score: -136.8\n",
      "episode: 11 best score: -120.3\n",
      "episode: 12 best score: -138.1\n",
      "episode: 13 best score: -122.4\n",
      "episode: 14 best score: -138.4\n",
      "episode: 15 best score: -122.0\n",
      "episode: 16 best score: -120.1\n",
      "episode: 17 best score: -128.2\n",
      "episode: 18 best score: -127.7\n",
      "episode: 19 best score: -137.2\n",
      "episode: 20 best score: -139.6\n",
      "episode: 21 best score: -118.5\n",
      "episode: 22 best score: -119.3\n",
      "episode: 23 best score: -118.5\n",
      "episode: 24 best score: -119.5\n",
      "episode: 25 best score: -121.4\n",
      "episode: 26 best score: -127.5\n",
      "episode: 27 best score: -120.3\n",
      "episode: 28 best score: -122.2\n",
      "episode: 29 best score: -120.6\n"
     ]
    }
   ],
   "source": [
    "# No curiousity\n",
    "bot = train(env, pop_size, trials_per_individual, survival_rate, prob_mutate, std, num_episodes, verbose=True, goal=-110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0 best score: -199.11\n",
      "episode: 1 best score: -198.94\n",
      "episode: 2 best score: -198.65\n",
      "episode: 3 best score: -198.80\n",
      "episode: 4 best score: -198.79\n",
      "episode: 5 best score: -199.09\n",
      "episode: 6 best score: -198.79\n",
      "episode: 7 best score: -161.71\n",
      "episode: 8 best score: -152.69\n",
      "episode: 9 best score: -135.37\n",
      "episode: 10 best score: -137.90\n",
      "episode: 11 best score: -152.23\n",
      "episode: 12 best score: -126.30\n",
      "episode: 13 best score: -121.35\n",
      "episode: 14 best score: -129.43\n",
      "episode: 15 best score: -123.07\n",
      "episode: 16 best score: -126.28\n",
      "episode: 17 best score: -127.81\n",
      "episode: 18 best score: -126.19\n",
      "episode: 19 best score: -122.47\n",
      "episode: 20 best score: -122.38\n",
      "episode: 21 best score: -119.14\n",
      "episode: 22 best score: -118.11\n",
      "episode: 23 best score: -116.42\n",
      "episode: 24 best score: -119.36\n",
      "episode: 25 best score: -121.57\n",
      "episode: 26 best score: -120.77\n",
      "episode: 27 best score: -118.93\n",
      "episode: 28 best score: -120.58\n",
      "episode: 29 best score: -117.93\n"
     ]
    }
   ],
   "source": [
    "bot = train(env, pop_size, trials_per_individual, survival_rate, prob_mutate, std, num_episodes, curiousity=True, verbose=True, goal=-110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(env,bot,render=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
